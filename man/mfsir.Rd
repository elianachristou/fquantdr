% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mfsir.R
\name{mfsir}
\alias{mfsir}
\title{Functional Sliced Inverse Regression}
\usage{
mfsir(X, y, H, nbasis)
}
\arguments{
\item{X}{A 3-dimensional array (\code{n x nt x p}), where n is the number
of observations, nt is the number of time points, and p is the number
of predictor variables.}

\item{y}{A numeric vector of length \code{n} representing the response
variable.}

\item{H}{The number of slices for the response variable.}

\item{nbasis}{The number of basis functions for the B-spline basis.}
}
\value{
\code{mfsir} computes the new sufficient predictors and returns
\item{xcoef}{A \code{n x (p * nbasis)} matrix of smoothed and centered
coefficients for the functional predictors using B-spline basis functions.}
\item{eigvalues}{The eigenvalues resulting from the eigenvalue decomposition
of the matrix of interest that is calculated during the dimension
reduction process.}
\item{phi}{A \code{(p * nbasis) x (p * nbasis)} matrix of eigenvectors
resulting from the eigenvalue decomposition of the matrix of interest
that is calculated during the dimension reduction process.}
\item{gx}{The \code{(p * nbasis) x (p * nbasis)} block diagonal Gram
matrix of the B-spline basis functions.}
\item{betas}{The coordinates of \eqn{\beta_1, \dots, \beta_d} resulting
from the coordinate representation on the B-spline basis functions.}
\item{sufpred}{The estimated sufficient predictors of the functional
central subspace.}
}
\description{
\code{mfsir} performs dimension reduction for functional data and
provides the new estimated predictors.
}
\details{
This function performs functional sliced inverse regression (FSIR),
introduced by Ferr\'e and Yao (2003), for scalar-on-function problem.
The authors proved that \eqn{E(X|Y) - E(X)} belongs to
\eqn{\Sigma_{XX} S_{Y|X}}, where \eqn{S_{Y|X}} denotes the functional
central subspace.

For \eqn{i=1, \dots, p}, let \eqn{\mathcal{H}_i} be a separable
Hilbert space of real-valued functions on \eqn{T}, a bounded closed interval
in \eqn{\mathbb{R}}.  Let \eqn{Y: \Omega \rightarrow \mathbb{R}} a univariate
response and \eqn{X=(X^1, \dots, X^p): \Omega \rightarrow
\bigoplus_{i=1}^p \mathcal{H}_i} a random element.  Dimension reduction
techniques aim at finding functions \eqn{\beta_1, \dots, \beta_d} in
\eqn{\bigoplus_{i=1}^p \mathcal{H}_i}, such that
\deqn{Y = g(\langle \beta_1, X \rangle_{\bigoplus \mathcal{H}}, \dots,
\langle \beta_d, X \rangle_{\bigoplus \mathcal{H}}, \epsilon),} where
\eqn{g} is an arbitrary unknown function on \eqn{\mathbb{R}^{d+1}}, and
\eqn{\epsilon} is independent of \eqn{X}.  This implies that \eqn{Y} and
\eqn{X} are independent given \eqn{\langle \beta_1,
X \rangle_{\bigoplus \mathcal{H}}, \dots,
\langle \beta_d, X \rangle_{\bigoplus \mathcal{H}}} and that the \eqn{p}-
dimensional predictor \eqn{X} can be replace with the \eqn{d}-dimensional
predictor \eqn{\langle \beta_1, X \rangle_{\bigoplus \mathcal{H}}, \dots,
\langle \beta_d, X \rangle_{\bigoplus \mathcal{H}}}.

The functions \eqn{\beta_1, \dots, \beta_d} are called the \emph{functional
dimension reduction directions} and the subspace spanned by \eqn{\beta_1,
\dots, \beta_d} is called the \emph{functional dimension reduction
subspace}.  The smallest functional dimension reduction subspace is called
the \emph{functional central subspace} and is denoted by \eqn{S_{Y|X}}.
}
\examples{
# set the parameters
n <- 100
p <- 5
nt <- 101
nbasis <- 4
H <- 10
time <- seq(0, 1, length.out = nt)
eta <- matrix(stats::rnorm(n * p * nbasis), nrow = n,
    ncol = p * nbasis)
# Generate the functional data
result <- fundata(n, p, nbasis, time, eta)
Xc <- result$xc
P <- eigen(stats::cov(eta))$vectors
mfpca.scores <- eta \%*\% P
# Generate the model
error <- rnorm(n)
y <- 3 * mfpca.scores[, 1] + error
# Run mfsir
result <- mfsir(Xc, y, H, nbasis)
result$sufpred
# Plot the first sufficient predictor against the true one
plot(result$sufpred[, 1], mfpca.scores[, 1], xlab = 'First
    Sufficient Predictor', ylab = 'True Predictor')
# Calculate the correlation between the estimated and true predictors
mcorr(result$sufpred[, 1], mfpca.scores[, 1])

}
\references{
Ferr\'e, L, and Yao, F. (2003) Function Sliced Inverse Regression
Analysis. \emph{Statistics}, 37(6), 475-488.
}
